# 2018-ACM-ICPC-SoCal-Regional
We went to the SoCal ICPC regional and got 3rd.  Here's our code and a brief postmortem.  Brief disclaimer: I hand-copied the code from a Linux box running off of a USB that we got after the contest, since our login didn't work for some reason.  So some code is probably typed wrong, although I'm fairly sure that it'll all compile and run (but maybe not get the right answer).

[Final standings](http://socalcontest.org/history/2018/Scoreboard-2018.shtml)

[Problems](http://socalcontest.org/history/2018/SC2018ICPCProblems.pdf)


Postmortem:

(it's basically two week late, so take it with a grain of salt)

Going into the competition we though it was going to be 10 questions, so we split the initial reading 3-4-3, with Victor reading the first segment, Sean reading the middle, and me reading the end.  It was actually 11, so I just took the last four instead.

Initial impressions:

(feel free to fill in your own impressions here)

I personally started reading from 11 backwards through 8 for some reason.  11 looked a bit like a knapsack, so I left that for later.  10 was number theory, and we'd had some tricky number theory in recent practices, so I tabled that one as well.  9 stuck out as comparatively really easy, just a straightforward simulation.  Finally, 8 seemed doable but with some very annoying input -- I naively assumed that if the question had tricky input, the algorithm is probably pretty simple (how wrong I was).

Problem-by-problem, chronologically:

It didn't seem like either of Victor or Sean's segments had any particularly simple questions at the time, so I just hopped on the computer to start doing 9.  The algorithm was in fact as easy as I had predicted (just read in the probabilities associated with each letter, and multiply all the letter probabilities in a word to find the total probability of reading it correctly, since the probabilities are independent), but unfortunately a few implementation details prevented me from getting it until very late into the contest.  First of all, the sample test case in the packet was extraordinarily misleading -- the first word, "PR0GRAM" has a 0 in the middle instead of an O, which had me absolutely convinced that I was misreading the problem statement somehow.  Then, after that, reading in the input was a nontrivial task in C++.  If you look at 9.cpp, you'll see my attempted workaround that doesn't work if the first word after reading the letter probabilities happens to also be one character long.  I eventually had to recode it in Python, which immediately fixed it, but in between gave the computer up to Sean to code 6.

6 was made a lot easier in Python, where the function int(s) can take an optional second argument that is the base you want to convert it into.  It looks like a brute force on the two bases for the two different integers, with some amount of pruning to avoid erroring if you can't convert a string to a particular base.  All in all, I probably should've ceded to him earlier, instead of bashing against 9 for so long (and started by using Python instead of trying to use C++'s input).  Either way, we got the first two questions done in the first hour, which put us fairly far down the standings, but still top 10 if I recall correctly.

In the meantime, Victor had been working on 1, which he was able to finish pretty quickly after a brief mishap with the "No mismatches" case.  Essentially the algorithm goes like this: store the list of backup images in a set for quick access, and then for each backup file name, scans backwards through the file name for the second-to-last underscore (since the image name can include underscores, which messed up at least one other team of ours), and adds the full backup file name to a dictionary from image names to lists of corresponding backup file names.  Then from there it's straightforward to see which image file names don't have any backup files and which backup files are orphaned.  Another question which is much easier to do in Python because of its input format.

At the time, 10 and 11 seemed like the next-most approachable, so Sean was working on 11 using DP and I was looking at a brute-force method of doing 10.  As always, brute-force is much easier to code than DP, so I took the computer next to do 10.  The problem essentially boils down to quickly finding the prime factors of a number, which I did by first sieving to find all primes less than 2,000,000 and then just using it to find the list of factors of a, b, and a+b=c -- rad(a * b * c) = (product of list of primes of a) * (... of b) * (... of c), as long as a and b don't share any prime factors.  I wasn't quite sure about the running time of a sieve but was fairly certain that over all of the runs in a particular test case memoizing the list of primes would help.  To be honest, I really should have thought more about the time complexity of the algorithm as a whole, because as it is now, it looks like it's extremely close to TLEing.  A simple prune would be to cut off the factoring algorithm when the current prime you're looking at is greater than n, but even the list of primes will be fairly short (~150,000) so that really shouldn't be a problem.  Also for some reason the contest time limits were ~30 seconds, so there were essentially no problems with TLE.

I was slightly on the wrong track when I judged 11 to be a knapsack problem.  Sean (being our resident math major) quickly saw the DP approach: first generate a 2D DP array ways\[# dice\]\[value\] where dp\[n\]\[v\] = the number of ways to get a value of v by rolling n dice (distinguishable), and then use a bit of bruteforce to check every subset of the initially-rolled dice to see how many ways there were to roll them and have the resulting total be the target, T.  If you have the number of ways to reroll the subset of dice and reach the target, the probability that you do so is (# ways) / (6^(size of subset)).  Ultimately you want to choose the largest of these probabilities, and if tied then the smallest subset size.  Personally, I was worried at first about the time complexity of the algorithm, but it fits incredibly neatly.  Filling the DP array takes O(K^3) with a large constant, but it's still quite fast enough; the brute force takes O(K * 2^K), which dominates the running time but is still less than a billion and certainly fast enough compared to a 30 second time limit.  It seemed like this solution was particularly tricky to debug, but Sean got it in quite quickly.  In fact we solved 11 the fastest out of any team, with only 8 teams out of 100 getting it.  This was right at 2 hours, and we had solved 5 questions total, putting us in the top 5 at the time.
